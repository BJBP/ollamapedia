# Página Web de Streaming con Ollama

[![en](https://img.shields.io/badge/lang-en-blue.svg)](README.md)
[![es](https://img.shields.io/badge/lang-es-green.svg)](README_ES.md)

[English](README.md) | [Español](README_ES.md)

Una página web simple que se conecta a Ollama usando el modelo phi4-mini:latest y utiliza respuestas de streaming.

Este proyecto proporciona una interfaz web básica para interactuar con el modelo de lenguaje Ollama. Permite a los usuarios ingresar un prompt y recibir una respuesta en tiempo real y fragmentada del modelo.

## Tabla de Contenido

*   [Acerca de](#acerca-de)
*   [Instalación](#instalación)
*   [Uso](#uso)
*   [Contribución](#contribución)
*   [Licencia](#licencia)

## Acerca de

Este proyecto demuestra cómo crear una página web que se conecta al modelo de lenguaje Ollama y muestra respuestas de streaming. Utiliza HTML, CSS y JavaScript para crear una interfaz de usuario simple e interactiva.

## Instalación

1.  Asegúrate de tener Ollama instalado y en ejecución.
2.  Clona el repositorio:

```bash
git clone https://github.com/your-username/your-project.git
```

3.  Navega al directorio del proyecto:

```bash
cd your-project
```

4.  Abre el archivo `index.html` en tu navegador.

## Uso

1.  Escribe tu prompt en el campo de entrada y haz clic en el botón "Enviar".
2.  La respuesta de Ollama se mostrará en el div de salida.

## Contribución

¡Las contribuciones son bienvenidas! Por favor, envía una solicitud de extracción con tus cambios.

## Licencia

MIT